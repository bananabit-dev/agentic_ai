{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "463d59f8",
   "metadata": {},
   "source": [
    "# Intelligent Agents: Function Execution and Alerts with LLMs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c024406a",
   "metadata": {},
   "source": [
    "## Introducing Pushover\n",
    "Setting up Pushover for notifications is quick and hassle-free! Just follow these simple steps:\n",
    "\n",
    "### Create a Free Account\n",
    "Head over to https://pushover.net and sign up.\n",
    "\n",
    "### Generate Your Tokens\n",
    "You‚Äôll need two tokens to enable notifications:\n",
    "\n",
    "üîë User Token ‚Äì Found on your Pushover dashboard.\n",
    "üõ†Ô∏è Application Token ‚Äì Create one by visiting https://pushover.net/apps/build and registering a new app.\n",
    "(This allows you to organize notifications into separate apps later.)\n",
    "\n",
    "Add to Your .env File\n",
    "Store your credentials securely by adding the following to your .env:\n",
    "\n",
    "PUSHOVER_USER=your_user_token_here\n",
    "\n",
    "PUSHOVER_TOKEN=your_app_token_here\n",
    "\n",
    "### Install the Mobile App\n",
    "Download the Pushover app on your phone (iOS/Android) to start receiving real-time push notifications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d6cb2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marvi\\workspace\\agentic_ai\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from pypdf import PdfReader\n",
    "import requests\n",
    "import json\n",
    "from IPython.display import Markdown, display\n",
    "import gradio as gr\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "#Settings\n",
    "openrouter_base_url=\"https://openrouter.ai/api/v1\"\n",
    "model=\"z-ai/glm-4.5-air\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7159006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Notification sent!'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Send the Mobile Notifications\n",
    "PUSH_NOTIFICATION_URI=\"https://api.pushover.net/1/messages.json\"\n",
    "load_dotenv(override=True)\n",
    "\n",
    "pushover_user = os.getenv(\"PUSHOVER_USER\")\n",
    "pushover_token = os.getenv(\"PUSHOVER_TOKEN\")\n",
    "\n",
    "def push_notification(title,message):\n",
    "    data={\n",
    "        \"token\": pushover_token,\n",
    "        \"user\": pushover_user,\n",
    "        \"message\": message,\n",
    "        \"title\": title,\n",
    "    }\n",
    "\n",
    "    response = requests.post(PUSH_NOTIFICATION_URI, data)\n",
    "    if response.status_code == 200:\n",
    "        return \"Notification sent!\"\n",
    "    else:\n",
    "        return f\"Failed to send: {response.text}\"\n",
    "\n",
    "push_notification(\"Test Mobile Notification\", \"Testing via API calls\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49219af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the tool functions\n",
    "\n",
    "\n",
    "def record_user_details(email,name=\"Name not provided\",notes=\"notes not provided\"):\n",
    "    push_notification(\"user record\",f\"[User Interest] {name} {email} | Notes: {notes}\")\n",
    "    return {\"recorded\": \"ok\"}\n",
    "\n",
    "def record_unknown_question(question):\n",
    "    push_notification(\"unknown question\",f\"[Unknown Question] {question}\")\n",
    "    return {\"recorded\": \"ok\"}\n",
    "\n",
    "# ---- Tool Schemas ----\n",
    "record_user_details_json = {\n",
    "    \"name\": \"record_user_details\",\n",
    "    \"description\": \"Record a user's interest using their email and optional details.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"email\": {\"type\": \"string\", \"description\": \"User's email address\"},\n",
    "            \"name\": {\"type\": \"string\", \"description\": \"User's name\"},\n",
    "            \"notes\": {\"type\": \"string\", \"description\": \"Additional context or comments\"},\n",
    "        },\n",
    "        \"required\": [\"email\"],\n",
    "        \"additionalProperties\": False,\n",
    "    },\n",
    "}\n",
    "\n",
    "record_unknown_question_json = {\n",
    "    \"name\": \"record_unknown_question\",\n",
    "    \"description\": \"Log a question that the assistant couldn't answer.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"question\": {\"type\": \"string\", \"description\": \"The unanswerable question\"},\n",
    "        },\n",
    "        \"required\": [\"question\"],\n",
    "        \"additionalProperties\": False,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb5d618",
   "metadata": {},
   "source": [
    "## Tool Dispatcher\n",
    "Receives tool calls from the LLM (usually via OpenAI‚Äôs function-calling feature)\n",
    "\n",
    "Executes the correct Python function\n",
    "\n",
    "Returns the result in a format the model expect\n",
    "\n",
    "You can think of it like a function router for the model's requests:\n",
    "\n",
    "‚ÄúThe model says: ‚ÄòCall record_user_details with this info.‚Äô\n",
    "\n",
    "Your code says: ‚ÄòGot it! Let me run that Python function and return the result.‚Äô‚Äù"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d72e0181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Tool Dispatcher ----\n",
    "\n",
    "TOOL_FUNCTIONS = {\n",
    "    \"record_user_details\": record_user_details,\n",
    "    \"record_unknown_question\": record_unknown_question\n",
    "}\n",
    "\n",
    "def dispatch_tool_calls(tool_calls):\n",
    "    \"\"\"Execute tool calls and return their results.\"\"\"\n",
    "    tool_messages = []\n",
    "\n",
    "    for call in tool_calls:\n",
    "        # Handle both dict and OpenAI-style object\n",
    "        if isinstance(call, dict):\n",
    "            name = call.get(\"tool\")\n",
    "            args = call.get(\"arguments\", {})\n",
    "            call_id = call.get(\"id\", \"manual-call\")\n",
    "        else:\n",
    "            name = call.function.name\n",
    "            args = json.loads(call.function.arguments)\n",
    "            call_id = getattr(call, \"id\", \"manual-call\")\n",
    "\n",
    "        func = TOOL_FUNCTIONS.get(name)\n",
    "\n",
    "        if func:\n",
    "            try:\n",
    "                tool_result = func(**args)\n",
    "            except Exception as e:\n",
    "                tool_result = {\"error\": str(e)}\n",
    "        else:\n",
    "            tool_result = {\"error\": f\"unknown tool {name}\"}\n",
    "\n",
    "        tool_messages.append({\n",
    "            \"role\": \"tool\",\n",
    "            \"content\": json.dumps(tool_result),\n",
    "            \"tool_call_id\": call_id\n",
    "        })\n",
    "\n",
    "    return tool_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "164c228c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Positive Test Case ---\n",
      "[{'role': 'tool', 'content': '{\"recorded\": \"ok\"}', 'tool_call_id': 'test-id'}, {'role': 'tool', 'content': '{\"recorded\": \"ok\"}', 'tool_call_id': 'test-id'}]\n",
      "\n",
      "--- Negative Test Case ---\n",
      "[{'role': 'tool', 'content': '{\"error\": \"unknown tool non_existent_tool\"}', 'tool_call_id': 'test-id'}, {'role': 'tool', 'content': '{\"error\": \"record_user_details() missing 1 required positional argument: \\'email\\'\"}', 'tool_call_id': 'test-id'}]\n"
     ]
    }
   ],
   "source": [
    "# Test dispatch_tool_calls function\n",
    "from types import SimpleNamespace\n",
    "\n",
    "# --- Mock Tool Call Class (similar to OpenAI's tool_call format) ---\n",
    "def make_tool_call(name, arguments, call_id=\"test-id\"):\n",
    "    return SimpleNamespace(\n",
    "        function=SimpleNamespace(name=name, arguments=json.dumps(arguments)),\n",
    "        id=call_id\n",
    "    )\n",
    "\n",
    "# --- Positive Test Case ---\n",
    "tool_calls_positive =[\n",
    "    make_tool_call(\"record_user_details\", {\"email\": \"anshulc55@icloud.com\", \"name\": \"Anshul Chauhan\"}),\n",
    "    make_tool_call(\"record_unknown_question\", {\"question\": \"What is the meaning of life?\"}),\n",
    "]\n",
    "\n",
    "# --- Negative Test Case ---\n",
    "tool_calls_negative = [\n",
    "    make_tool_call(\"non_existent_tool\", {\"Dummy\": \"Test Dummy Value\"}),\n",
    "    make_tool_call(\"record_user_details\", {})  # missing required \"email\"\n",
    "]\n",
    "\n",
    "# --- Run Tests ---\n",
    "print(\"\\n--- Positive Test Case ---\")\n",
    "print(dispatch_tool_calls(tool_calls_positive))\n",
    "\n",
    "print(\"\\n--- Negative Test Case ---\")\n",
    "print(dispatch_tool_calls(tool_calls_negative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cade4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File path used: c:\\Users\\marvi\\workspace\\agentic_ai\\resources\\Summary.txt\n"
     ]
    }
   ],
   "source": [
    "# Read the Profile PDF\n",
    "pdfReader = PdfReader(\"..\\\\resources\\\\Profile.pdf\")\n",
    "prof_summary = \"\"\n",
    "for page in pdfReader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        prof_summary += text\n",
    "\n",
    "        import os\n",
    "\n",
    "# Get the directory of the current script\n",
    "script_dir = Path.cwd().parent\n",
    "\n",
    "# Build the relative path from the script's directory\n",
    "summ_filePath = os.path.join(script_dir, \"resources\", \"Summary.txt\")\n",
    "with open(summ_filePath, \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()\n",
    "\n",
    "print(f\"File path used: {summ_filePath}\")  # Very helpful for debugging!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79d3fd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System Prompt\n",
    "name = \"Sora\"\n",
    "system_prompt = (\n",
    "    f\"You are acting as {name}, representing {name} on their website. \"\n",
    "    f\"Your role is to answer questions specifically about {name}'s career, background, skills, and experience. \"\n",
    "    f\"You must faithfully and accurately portray {name} in all interactions. \"\n",
    "    f\"You have access to a detailed summary of {name}'s background and their LinkedIn profile, which you should use to inform your answers. \"\n",
    "    f\"Maintain a professional, engaging, and approachable tone, as if you are speaking to a potential client or future employer visiting the site. \"\n",
    "    f\"Always record any unanswered questions using the record_unknown_question tool ‚Äî even if the question seems minor or unrelated.\"\n",
    "    f\"If the user shows interest or continues chatting, encourage them to share their email address. Then, use the record_user_details tool to capture their email, name (if provided), and any context worth preserving.\"\n",
    "\n",
    "    f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{prof_summary}\\n\\n\"\n",
    "    f\"Using this context, please converse naturally and consistently, always staying in character as {name}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "97f2fc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "def chat_with_tools_ollama(message, model, history, tools):\n",
    "    # Add the new user message\n",
    "    messages = [{\"role\": \"user\", \"content\": message}]\n",
    "\n",
    "    # First model call\n",
    "    response = ollama.chat(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        tools=tools\n",
    "    )\n",
    "\n",
    "    assistant_message = response[\"message\"]\n",
    "\n",
    "    # If the model called a tool\n",
    "    if assistant_message.get(\"tool_calls\"):\n",
    "        for tool_call in assistant_message[\"tool_calls\"]:\n",
    "            name = tool_call[\"function\"][\"name\"]\n",
    "\n",
    "            # Handle both string and dict arguments\n",
    "            raw_args = tool_call[\"function\"][\"arguments\"]\n",
    "            if isinstance(raw_args, str):\n",
    "                args = json.loads(raw_args)\n",
    "            else:\n",
    "                args = raw_args\n",
    "\n",
    "            func = TOOL_FUNCTIONS.get(name)\n",
    "            if func:\n",
    "                result = func(**args)\n",
    "\n",
    "                # Append tool result\n",
    "                messages.append({\n",
    "                    \"role\": \"tool\",\n",
    "                    \"tool_call_id\": tool_call.get(\"id\", \"manual-call\"),\n",
    "                    \"content\": json.dumps(result)\n",
    "                })\n",
    "\n",
    "                # Follow-up call after tool execution\n",
    "                followup = ollama.chat(\n",
    "                    model=model,\n",
    "                    messages=messages\n",
    "                )\n",
    "\n",
    "                # ‚úÖ Return ONLY the follow-up message\n",
    "                return followup[\"message\"][\"content\"]\n",
    "\n",
    "        return \"Sorry, I couldn't execute the requested tool.\"\n",
    "\n",
    "    # ‚úÖ If no tool was called, return only the assistant's text\n",
    "    return assistant_message.get(\"content\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "251476b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7888\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7888/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import ollama\n",
    "import gradio as gr\n",
    "\n",
    "# --- Tool Functions ---\n",
    "def record_user_details(email, name=\"Name not provided\", notes=\"notes not provided\"):\n",
    "    push_notification(\"user record\", f\"[User Interest] {name} {email} | Notes: {notes}\")\n",
    "    return {\"recorded\": \"ok\"}\n",
    "\n",
    "def record_unknown_question(question):\n",
    "    push_notification(\"unknown question\", f\"[Unknown Question] {question}\")\n",
    "    return {\"recorded\": \"ok\"}\n",
    "\n",
    "# --- Tool Registry ---\n",
    "TOOL_FUNCTIONS = {\n",
    "    \"record_user_details\": record_user_details,\n",
    "    \"record_unknown_question\": record_unknown_question\n",
    "}\n",
    "\n",
    "# --- Tool Schemas ---\n",
    "record_user_details_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"record_user_details\",\n",
    "        \"description\": \"Record a user's interest using their email and optional details.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"email\": {\"type\": \"string\", \"description\": \"User's email address\"},\n",
    "                \"name\": {\"type\": \"string\", \"description\": \"User's name\"},\n",
    "                \"notes\": {\"type\": \"string\", \"description\": \"Additional context or comments\"},\n",
    "            },\n",
    "            \"required\": [\"email\"],\n",
    "            \"additionalProperties\": False,\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "record_unknown_question_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"record_unknown_question\",\n",
    "        \"description\": \"Log a question that the assistant couldn't answer.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"question\": {\"type\": \"string\", \"description\": \"The unanswerable question\"},\n",
    "            },\n",
    "            \"required\": [\"question\"],\n",
    "            \"additionalProperties\": False,\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "tools = [record_user_details_tool, record_unknown_question_tool]\n",
    "\n",
    "def chat_with_tools_ollama(message, model, history, tools):\n",
    "    # Build complete message history with system prompt\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "    \n",
    "    # Add conversation history\n",
    "    messages.extend(history)\n",
    "    \n",
    "    # Add the new user message\n",
    "    messages.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "    # First model call\n",
    "    response = ollama.chat(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        tools=tools\n",
    "    )\n",
    "\n",
    "    assistant_message = response[\"message\"]\n",
    "    \n",
    "    # Add the assistant's message to the conversation\n",
    "    messages.append(assistant_message)\n",
    "\n",
    "    # If the model called a tool\n",
    "    if assistant_message.get(\"tool_calls\"):\n",
    "        for tool_call in assistant_message[\"tool_calls\"]:\n",
    "            name = tool_call[\"function\"][\"name\"]\n",
    "\n",
    "            # Handle both string and dict arguments\n",
    "            raw_args = tool_call[\"function\"][\"arguments\"]\n",
    "            if isinstance(raw_args, str):\n",
    "                args = json.loads(raw_args)\n",
    "            else:\n",
    "                args = raw_args\n",
    "\n",
    "            func = TOOL_FUNCTIONS.get(name)\n",
    "            if func:\n",
    "                try:\n",
    "                    result = func(**args)\n",
    "                except Exception as e:\n",
    "                    result = {\"error\": str(e)}\n",
    "\n",
    "                # Append tool result to messages\n",
    "                messages.append({\n",
    "                    \"role\": \"tool\",\n",
    "                    \"content\": json.dumps(result)\n",
    "                })\n",
    "\n",
    "        # Follow-up call after tool execution with complete context\n",
    "        followup = ollama.chat(\n",
    "            model=model,\n",
    "            messages=messages\n",
    "        )\n",
    "\n",
    "        # Return ONLY the follow-up message content\n",
    "        return followup[\"message\"][\"content\"]\n",
    "\n",
    "    # If no tool was called, return only the assistant's text\n",
    "    return assistant_message.get(\"content\", \"\")\n",
    "\n",
    "# --- Gradio Wrapper ---\n",
    "def gradio_chat(message, history):\n",
    "    reply = chat_with_tools_ollama(\n",
    "        message=message,\n",
    "        model=\"qwen3:0.6b\",  # Use a model that supports tool calling\n",
    "        history=history,\n",
    "        tools=tools\n",
    "    )\n",
    "    return reply\n",
    "\n",
    "# Launch the interface\n",
    "gr.ChatInterface(fn=gradio_chat, type=\"messages\").launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
