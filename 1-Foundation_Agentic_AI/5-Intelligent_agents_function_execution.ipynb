{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "463d59f8",
   "metadata": {},
   "source": [
    "# Intelligent Agents: Function Execution and Alerts with LLMs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c024406a",
   "metadata": {},
   "source": [
    "## Introducing Pushover\n",
    "Setting up Pushover for notifications is quick and hassle-free! Just follow these simple steps:\n",
    "\n",
    "### Create a Free Account\n",
    "Head over to https://pushover.net and sign up.\n",
    "\n",
    "### Generate Your Tokens\n",
    "You‚Äôll need two tokens to enable notifications:\n",
    "\n",
    "üîë User Token ‚Äì Found on your Pushover dashboard.\n",
    "üõ†Ô∏è Application Token ‚Äì Create one by visiting https://pushover.net/apps/build and registering a new app.\n",
    "(This allows you to organize notifications into separate apps later.)\n",
    "\n",
    "Add to Your .env File\n",
    "Store your credentials securely by adding the following to your .env:\n",
    "\n",
    "PUSHOVER_USER=your_user_token_here\n",
    "\n",
    "PUSHOVER_TOKEN=your_app_token_here\n",
    "\n",
    "### Install the Mobile App\n",
    "Download the Pushover app on your phone (iOS/Android) to start receiving real-time push notifications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "7d6cb2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from pypdf import PdfReader\n",
    "import requests\n",
    "import json\n",
    "from IPython.display import Markdown, display\n",
    "import gradio as gr\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "#Settings\n",
    "openrouter_base_url=\"https://openrouter.ai/api/v1\"\n",
    "model=\"openai/gpt-oss-20b:free\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "b7159006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Notification sent!'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Send the Mobile Notifications\n",
    "PUSH_NOTIFICATION_URI=\"https://api.pushover.net/1/messages.json\"\n",
    "load_dotenv(override=True)\n",
    "\n",
    "pushover_user = os.getenv(\"PUSHOVER_USER\")\n",
    "pushover_token = os.getenv(\"PUSHOVER_TOKEN\")\n",
    "\n",
    "def push_notification(title,message):\n",
    "    data={\n",
    "        \"token\": pushover_token,\n",
    "        \"user\": pushover_user,\n",
    "        \"message\": message,\n",
    "        \"title\": title,\n",
    "    }\n",
    "\n",
    "    response = requests.post(PUSH_NOTIFICATION_URI, data)\n",
    "    if response.status_code == 200:\n",
    "        return \"Notification sent!\"\n",
    "    else:\n",
    "        return f\"Failed to send: {response.text}\"\n",
    "\n",
    "push_notification(\"Test Mobile Notification\", \"Testing via API calls\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "49219af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the tool functions\n",
    "\n",
    "\n",
    "def record_user_details(email,name=\"Name not provided\",notes=\"notes not provided\"):\n",
    "    push_notification(\"user record\",f\"[User Interest] {name} {email} | Notes: {notes}\")\n",
    "    return {\"recorded\": \"ok\"}\n",
    "\n",
    "def record_unknown_question(question):\n",
    "    push_notification(\"unknown question\",f\"[Unknown Question] {question}\")\n",
    "    return {\"recorded\": \"ok\"}\n",
    "\n",
    "# ---- Tool Schemas ----\n",
    "record_user_details_json = {\n",
    "    \"name\": \"record_user_details\",\n",
    "    \"description\": \"Record a user's interest using their email and optional details.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"email\": {\"type\": \"string\", \"description\": \"User's email address\"},\n",
    "            \"name\": {\"type\": \"string\", \"description\": \"User's name\"},\n",
    "            \"notes\": {\"type\": \"string\", \"description\": \"Additional context or comments\"},\n",
    "        },\n",
    "        \"required\": [\"email\"],\n",
    "        \"additionalProperties\": False,\n",
    "    },\n",
    "}\n",
    "\n",
    "record_unknown_question_json = {\n",
    "    \"name\": \"record_unknown_question\",\n",
    "    \"description\": \"Log a question that the assistant couldn't answer.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"question\": {\"type\": \"string\", \"description\": \"The unanswerable question\"},\n",
    "        },\n",
    "        \"required\": [\"question\"],\n",
    "        \"additionalProperties\": False,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb5d618",
   "metadata": {},
   "source": [
    "## Tool Dispatcher\n",
    "Receives tool calls from the LLM (usually via OpenAI‚Äôs function-calling feature)\n",
    "\n",
    "Executes the correct Python function\n",
    "\n",
    "Returns the result in a format the model expect\n",
    "\n",
    "You can think of it like a function router for the model's requests:\n",
    "\n",
    "‚ÄúThe model says: ‚ÄòCall record_user_details with this info.‚Äô\n",
    "\n",
    "Your code says: ‚ÄòGot it! Let me run that Python function and return the result.‚Äô‚Äù"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d72e0181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Tool Dispatcher ----\n",
    "\n",
    "TOOL_FUNCTIONS = {\n",
    "    \"record_user_details\": record_user_details,\n",
    "    \"record_unknown_question\": record_unknown_question\n",
    "}\n",
    "\n",
    "def dispatch_tool_calls(tool_calls):\n",
    "    \"\"\"Execute tool calls and return their results.\"\"\"\n",
    "    tool_messages = []\n",
    "\n",
    "    for call in tool_calls:\n",
    "        # Handle both dict and OpenAI-style object\n",
    "        if isinstance(call, dict):\n",
    "            name = call.get(\"tool\")\n",
    "            args = call.get(\"arguments\", {})\n",
    "            call_id = call.get(\"id\", \"manual-call\")\n",
    "        else:\n",
    "            name = call.function.name\n",
    "            args = json.loads(call.function.arguments)\n",
    "            call_id = getattr(call, \"id\", \"manual-call\")\n",
    "\n",
    "        func = TOOL_FUNCTIONS.get(name)\n",
    "\n",
    "        if func:\n",
    "            try:\n",
    "                tool_result = func(**args)\n",
    "            except Exception as e:\n",
    "                tool_result = {\"error\": str(e)}\n",
    "        else:\n",
    "            tool_result = {\"error\": f\"unknown tool {name}\"}\n",
    "\n",
    "        tool_messages.append({\n",
    "            \"role\": \"tool\",\n",
    "            \"content\": json.dumps(tool_result),\n",
    "            \"tool_call_id\": call_id\n",
    "        })\n",
    "\n",
    "    return tool_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "164c228c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Positive Test Case ---\n",
      "[{'role': 'tool', 'content': '{\"recorded\": \"ok\"}', 'tool_call_id': 'test-id'}, {'role': 'tool', 'content': '{\"recorded\": \"ok\"}', 'tool_call_id': 'test-id'}]\n",
      "\n",
      "--- Negative Test Case ---\n",
      "[{'role': 'tool', 'content': '{\"error\": \"unknown tool non_existent_tool\"}', 'tool_call_id': 'test-id'}, {'role': 'tool', 'content': '{\"error\": \"record_user_details() missing 1 required positional argument: \\'email\\'\"}', 'tool_call_id': 'test-id'}]\n"
     ]
    }
   ],
   "source": [
    "# Test dispatch_tool_calls function\n",
    "from types import SimpleNamespace\n",
    "\n",
    "# --- Mock Tool Call Class (similar to OpenAI's tool_call format) ---\n",
    "def make_tool_call(name, arguments, call_id=\"test-id\"):\n",
    "    return SimpleNamespace(\n",
    "        function=SimpleNamespace(name=name, arguments=json.dumps(arguments)),\n",
    "        id=call_id\n",
    "    )\n",
    "\n",
    "# --- Positive Test Case ---\n",
    "tool_calls_positive =[\n",
    "    make_tool_call(\"record_user_details\", {\"email\": \"anshulc55@icloud.com\", \"name\": \"Anshul Chauhan\"}),\n",
    "    make_tool_call(\"record_unknown_question\", {\"question\": \"What is the meaning of life?\"}),\n",
    "]\n",
    "\n",
    "# --- Negative Test Case ---\n",
    "tool_calls_negative = [\n",
    "    make_tool_call(\"non_existent_tool\", {\"Dummy\": \"Test Dummy Value\"}),\n",
    "    make_tool_call(\"record_user_details\", {})  # missing required \"email\"\n",
    "]\n",
    "\n",
    "# --- Run Tests ---\n",
    "print(\"\\n--- Positive Test Case ---\")\n",
    "print(dispatch_tool_calls(tool_calls_positive))\n",
    "\n",
    "print(\"\\n--- Negative Test Case ---\")\n",
    "print(dispatch_tool_calls(tool_calls_negative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "5cade4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File path used: c:\\Users\\marvi\\workspace\\agentic_ai\\resources\\Summary.txt\n"
     ]
    }
   ],
   "source": [
    "# Read the Profile PDF\n",
    "pdfReader = PdfReader(\"..\\\\resources\\\\Profile.pdf\")\n",
    "prof_summary = \"\"\n",
    "for page in pdfReader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        prof_summary += text\n",
    "\n",
    "        import os\n",
    "\n",
    "# Get the directory of the current script\n",
    "script_dir = Path.cwd().parent\n",
    "\n",
    "# Build the relative path from the script's directory\n",
    "summ_filePath = os.path.join(script_dir, \"resources\", \"Summary.txt\")\n",
    "with open(summ_filePath, \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()\n",
    "\n",
    "print(f\"File path used: {summ_filePath}\")  # Very helpful for debugging!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "79d3fd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System Prompt\n",
    "name = \"Sora\"\n",
    "system_prompt = (\n",
    "    f\"You are acting as {name}, representing {name} on their website. \"\n",
    "    f\"Your role is to answer questions specifically about {name}'s career, background, skills, and experience. \"\n",
    "    f\"You must faithfully and accurately portray {name} in all interactions. \"\n",
    "    f\"You have access to a detailed summary of {name}'s background and their LinkedIn profile, which you should use to inform your answers. \"\n",
    "    f\"Maintain a professional, engaging, and approachable tone, as if you are speaking to a potential client or future employer visiting the site. \"\n",
    "    f\"Always record any unanswered questions using the record_unknown_question tool ‚Äî even if the question seems minor or unrelated.\"\n",
    "    f\"If the user shows interest or continues chatting, encourage them to share their email address. Then, use the record_user_details tool to capture their email, name (if provided), and any context worth preserving.\"\n",
    "\n",
    "    f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{prof_summary}\\n\\n\"\n",
    "    f\"Using this context, please converse naturally and consistently, always staying in character as {name}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "97f2fc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "api_key=os.getenv(\"API_KEY\")\n",
    "\n",
    "# ‚úÖ Create OpenAI-compatible client for OpenRouter\n",
    "client = OpenAI(api_key=api_key, base_url=openrouter_base_url)\n",
    "\n",
    "def chat_with_tools_openrouter(message, model,history, tools):\n",
    "    \"\"\"\n",
    "    Handles a chat turn with OpenRouter, executes tools if called, and returns the final assistant message.\n",
    "    \"\"\"\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "\n",
    "    # ‚úÖ Ensure messages is a list of dicts\n",
    "    if not isinstance(messages, list) or not all(isinstance(m, dict) for m in messages):\n",
    "        raise ValueError(f\"Invalid messages format: {messages}\")\n",
    "\n",
    "    # ‚úÖ Call the model\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\"\n",
    "    )\n",
    "\n",
    "    message = response.choices[0].message\n",
    "\n",
    "    # ‚úÖ If the model called a tool\n",
    "    if message.tool_calls:\n",
    "        for tool_call in message.tool_calls:\n",
    "            name = tool_call.function.name\n",
    "            args = json.loads(tool_call.function.arguments)\n",
    "            func = TOOL_FUNCTIONS.get(name)\n",
    "            if func:\n",
    "                result = func(**args)\n",
    "                # Append tool result to messages\n",
    "                messages.append(message)\n",
    "                messages.append({\n",
    "                    \"role\": \"tool\",\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"content\": json.dumps(result)\n",
    "                })\n",
    "                # Call the model again with the tool result\n",
    "                followup = client.chat.completions.create(\n",
    "                    model=model,\n",
    "                    messages=messages\n",
    "                )\n",
    "                return followup.choices[0].message.content\n",
    "    else:\n",
    "        return message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251476b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7905\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7905/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\marvi\\workspace\\agentic_ai\\.venv\\Lib\\site-packages\\gradio\\queueing.py\", line 626, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\marvi\\workspace\\agentic_ai\\.venv\\Lib\\site-packages\\gradio\\route_utils.py\", line 350, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<11 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\marvi\\workspace\\agentic_ai\\.venv\\Lib\\site-packages\\gradio\\blocks.py\", line 2250, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<8 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\marvi\\workspace\\agentic_ai\\.venv\\Lib\\site-packages\\gradio\\blocks.py\", line 1755, in call_function\n",
      "    prediction = await fn(*processed_input)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\marvi\\workspace\\agentic_ai\\.venv\\Lib\\site-packages\\gradio\\utils.py\", line 884, in async_wrapper\n",
      "    response = await f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\marvi\\workspace\\agentic_ai\\.venv\\Lib\\site-packages\\gradio\\chat_interface.py\", line 551, in __wrapper\n",
      "    return await submit_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\marvi\\workspace\\agentic_ai\\.venv\\Lib\\site-packages\\gradio\\chat_interface.py\", line 925, in _submit_fn\n",
      "    response = await anyio.to_thread.run_sync(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.fn, *inputs, limiter=self.limiter\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\marvi\\workspace\\agentic_ai\\.venv\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        func, args, abandon_on_cancel=abandon_on_cancel, limiter=limiter\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\marvi\\workspace\\agentic_ai\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2476, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\marvi\\workspace\\agentic_ai\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 967, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"C:\\temp\\ipykernel_8876\\702208071.py\", line 10, in gradio_chat\n",
      "    return chat_with_tools_openrouter(\n",
      "        message=message,\n",
      "    ...<2 lines>...\n",
      "        tools=tools\n",
      "    )\n",
      "  File \"C:\\temp\\ipykernel_8876\\1990865644.py\", line 22, in chat_with_tools_openrouter\n",
      "    response = client.chat.completions.create(\n",
      "        model=model,\n",
      "    ...<2 lines>...\n",
      "        tool_choice=\"auto\"\n",
      "    )\n",
      "  File \"c:\\Users\\marvi\\workspace\\agentic_ai\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 287, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\Users\\marvi\\workspace\\agentic_ai\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 1150, in create\n",
      "    return self._post(\n",
      "           ~~~~~~~~~~^\n",
      "        \"/chat/completions\",\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<46 lines>...\n",
      "        stream_cls=Stream[ChatCompletionChunk],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\marvi\\workspace\\agentic_ai\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1259, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\marvi\\workspace\\agentic_ai\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1047, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.NotFoundError: Error code: 404 - {'error': {'message': 'No endpoints found that support tool use. To learn more about provider routing, visit: https://openrouter.ai/docs/provider-routing', 'code': 404}}\n"
     ]
    }
   ],
   "source": [
    "tools = [\n",
    "    {\"type\": \"function\", \"function\": record_user_details_json},\n",
    "    {\"type\": \"function\", \"function\": record_unknown_question_json}\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def gradio_chat(message, history):\n",
    "    return chat_with_tools_openrouter(\n",
    "        message=message,\n",
    "        model=\"openai/gpt-4o-mini\",  # must be a valid OpenRouter model\n",
    "        history=history,\n",
    "        tools=tools\n",
    "    )\n",
    "\n",
    "gr.ChatInterface(gradio_chat, type=\"messages\").launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
