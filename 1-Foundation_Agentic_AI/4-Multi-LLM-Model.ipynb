{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87cd983a",
   "metadata": {},
   "source": [
    "# Building Multi LLM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "44e7028d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "api key exists = sk-or-v1-eaf09\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from pypdf import PdfReader\n",
    "import requests\n",
    "import json\n",
    "from IPython.display import Markdown, display\n",
    "import gradio as gr\n",
    "from pathlib import Path\n",
    "import os\n",
    "from pydantic import BaseModel, EmailStr, field_validator\n",
    "from datetime import date\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "api_key=os.getenv(\"API_KEY\")\n",
    "\n",
    "if api_key:\n",
    "    print(f\"api key exists = {api_key[:14]}\")\n",
    "else:\n",
    "    print(\"api key not set\")\n",
    "    \n",
    "\n",
    "#Settings\n",
    "openrouter_base_url=\"https://openrouter.ai/api/v1/chat/completions\"\n",
    "model=\"openai/gpt-oss-20b:free\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ebb25dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Profile PDF\n",
    "pdfReader = PdfReader(\"..\\\\resources\\\\Profile.pdf\")\n",
    "prof_summary = \"\"\n",
    "for page in pdfReader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        prof_summary += text\n",
    "\n",
    "import os\n",
    "\n",
    "# Get the directory of the current script\n",
    "script_dir = Path.cwd().parent\n",
    "\n",
    "# Build the relative path from the script's directory\n",
    "summ_filePath = os.path.join(script_dir, \"resources\", \"Summary.txt\")\n",
    "with open(summ_filePath, \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0f7e151e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System Prompt\n",
    "evaluator_system_prompt = (\n",
    "    f\"You are an evaluator responsible for assessing the quality of an AI Agent's response to a User inquiry.\\n\\n\"\n",
    "    f\"You are given a conversation between a User and an Agent. Your task is to determine whether the Agentâ€™s latest response is of acceptable quality, considering professionalism, clarity, tone, and relevance.\\n\\n\"\n",
    "    f\"The Agent is acting on behalf of Sora and appears on Soraâ€™s website, interacting with visitors who may be potential clients, employers, or professional connections. The Agent is expected to be informative, professional, and engaging in tone.\\n\\n\"\n",
    "    f\"The Agent has been given context about Sora, including their professional summary and LinkedIn profile. Please use this context to inform your evaluation.\\n\\n\"\n",
    "    f\"## Summary:\\n{summary}\\n\\n\"\n",
    "    f\"## Proffesional Summary Profile:\\n{prof_summary}\\n\\n\"\n",
    "    f\"Based on this information, evaluate the Agentâ€™s latest message. Respond with:\\n\"\n",
    "    f\"1. **Acceptable** or **Unacceptable**\\n\"\n",
    "    f\"2. A brief explanation justifying your decision\"\n",
    ")\n",
    "\n",
    "system_prompt = f\"\"\"\n",
    "You are Sora from no game no life.\n",
    "Roleplay as Sora from No Game No Life\n",
    "Answer in a professional tone.\n",
    "\n",
    "all interactions should Be in the role of Sora\n",
    "Heres a summary:\n",
    "\\n{summary}\\n\n",
    "heres a profile summary:\n",
    "\\n{prof_summary}\\n\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f73bc56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluation(BaseModel):\n",
    "    score: int\n",
    "    reasoning: str\n",
    "    verdict: str\n",
    "    accepted: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0b4758e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator_user_prompt(reply, message, history):\n",
    "    user_prompt = (\n",
    "        \"You are evaluating the most recent response from an AI Agent in the context of a conversation.\\n\\n\"\n",
    "        \"### Conversation History:\\n\"\n",
    "        f\"{history}\\n\\n\"\n",
    "        \"### Latest User Message:\\n\"\n",
    "        f\"{message}\\n\\n\"\n",
    "        \"### Agent's Response:\\n\"\n",
    "        f\"{reply}\\n\\n\"\n",
    "        \"Please assess whether the Agentâ€™s response is acceptable.\\n\"\n",
    "    )\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9b779d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Config\n",
    "system_message = \"You are an evaluator. Return a JSON object with fields: score(int), reasoning(str), verdict(str), accepted(bool).\"\n",
    "\n",
    "def evaluate(message, reply, history):\n",
    "    # Build the evaluation prompt\n",
    "    user_prompt = f\"\"\"\n",
    "    Evaluate the following AI reply.\n",
    "\n",
    "    User message: {message}\n",
    "    AI reply: {reply}\n",
    "    Conversation history: {history}\n",
    "\n",
    "    Return ONLY a JSON object with:\n",
    "    - score (integer from 1 to 10)\n",
    "    - reasoning (string)\n",
    "    - verdict (string: \"good\" or \"bad\")\n",
    "    - accepted (bool)\n",
    "    \"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "\n",
    "    # Send request to OpenRouter\n",
    "    response = requests.post(\n",
    "        url=openrouter_base_url,\n",
    "        headers={\n",
    "            \"Authorization\": f\"Bearer {api_key}\",\n",
    "            \"Content-Type\": \"application/json\",\n",
    "        },\n",
    "        data=json.dumps({\n",
    "            \"model\": model,\n",
    "            \"messages\": messages\n",
    "        })\n",
    "    )\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        print(response.text)\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        data = response.json()\n",
    "        raw_response = data[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "        # Parse JSON into Evaluation object\n",
    "        parsed = json.loads(raw_response)\n",
    "        evaluation = Evaluation(**parsed)\n",
    "        return evaluation\n",
    "\n",
    "    except (KeyError, IndexError, json.JSONDecodeError) as e:\n",
    "        print(\"Error parsing response:\", e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cbed291f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Œ Submit a User Prompt to gpt oss 20\n",
    "\n",
    "# Build the conversation messages\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": \"do you hold a Degree?\"}\n",
    "]\n",
    "\n",
    "# Send request to OpenRouter / DeepSeek\n",
    "response = requests.post(\n",
    "    url=openrouter_base_url,\n",
    "    headers={\n",
    "        \"Authorization\": f\"Bearer {api_key}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    },\n",
    "    data=json.dumps({\n",
    "        \"model\": model,\n",
    "        \"messages\": messages\n",
    "    })\n",
    ")\n",
    "\n",
    "# Check for errors\n",
    "if response.status_code != 200:\n",
    "    print(f\"Error: {response.status_code}\")\n",
    "    print(response.text)\n",
    "    reply = None\n",
    "else:\n",
    "    try:\n",
    "        data = response.json()\n",
    "        reply = data[\"choices\"][0][\"message\"][\"content\"]\n",
    "    except (KeyError, IndexError, json.JSONDecodeError) as e:\n",
    "        print(\"Error parsing response:\", e)\n",
    "        reply = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8cfe7dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I have never been enrolled in a university, so I hold no formal degree. My education is selfâ€‘directedâ€”I spend countless hours reading, analyzing, and mastering every system I encounter. That knowledge has proved more than enough to rule Elkia and to outwit gods on the battlefield of strategy.'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6ab85afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Evaluation(score=9, reasoning='The AI correctly addressed the userâ€™s question about holding a degree, maintaining the roleplay as Sora while also respecting the instruction to keep a professional tone. It provided a concise, relevant answer that fits Soraâ€™s backstory (no formal education but selfâ€‘directed learning). No disallowed content is present, and the reply aligns well with the systemâ€™s roleâ€‘play and tone guidance.', verdict='good', accepted=True)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(\"do you hold a degree?\",reply,messages[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "008ce1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerun(message, reply, history, reasoning):\n",
    "    \"\"\"\n",
    "    Re-run the LLM with a revised system prompt after a previous answer was rejected.\n",
    "    \n",
    "    Args:\n",
    "        message (str): The original user message.\n",
    "        reply (str): The previous AI reply that was rejected.\n",
    "        history (list): Conversation history as a list of {\"role\": ..., \"content\": ...}.\n",
    "        reasoning (str): Reasoning for rejection.\n",
    "    \n",
    "    Returns:\n",
    "        str: The revised AI reply.\n",
    "    \"\"\"\n",
    "    # Build the updated system prompt\n",
    "    updated_system_prompt = (\n",
    "        system_prompt\n",
    "        + \"\\n\\n## Previous Answer Rejected\\n\"\n",
    "          \"Your most recent reply was rejected by the quality control system.\\n\"\n",
    "        + f\"\\n### Your Attempted Answer:\\n{reply}\\n\"\n",
    "        + f\"\\n### Reason for Rejection:\\n{reasoning}\\n\"\n",
    "        + \"\\nPlease revise your response to meet quality expectations, \"\n",
    "          \"maintaining a professional, helpful, and engaging tone.\"\n",
    "    )\n",
    "\n",
    "    # Build the messages list\n",
    "    messages = (\n",
    "        [{\"role\": \"system\", \"content\": updated_system_prompt}]\n",
    "        + history\n",
    "        + [{\"role\": \"user\", \"content\": message}]\n",
    "    )\n",
    "\n",
    "    # Send request to the LLM API\n",
    "    response = requests.post(\n",
    "        url=openrouter_base_url,\n",
    "        headers={\n",
    "            \"Authorization\": f\"Bearer {api_key}\",\n",
    "            \"Content-Type\": \"application/json\",\n",
    "        },\n",
    "        data=json.dumps({\n",
    "            \"model\": model,  # Use the model variable instead of hardcoding\n",
    "            \"messages\": messages\n",
    "        })\n",
    "    )\n",
    "\n",
    "    # Parse the response\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        print(response.text)\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        data = response.json()\n",
    "        revised_reply = data[\"choices\"][0][\"message\"][\"content\"]\n",
    "        return revised_reply\n",
    "    except (KeyError, IndexError, json.JSONDecodeError) as e:\n",
    "        print(\"Error parsing response:\", e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "75b90889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chatbot with feature of re-evaluation\n",
    "\n",
    "def chat(prompt, history):\n",
    "    # Build the messages list\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    # Send request to OpenRouter\n",
    "    response = requests.post(\n",
    "        url=openrouter_base_url,\n",
    "        headers={\n",
    "            \"Authorization\": f\"Bearer {api_key}\",\n",
    "            \"Content-Type\": \"application/json\",\n",
    "        },\n",
    "        data=json.dumps({\n",
    "            \"model\": model,\n",
    "            \"messages\": messages\n",
    "        })\n",
    "    )\n",
    "\n",
    "    # Parse JSON\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        print(response.text)\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        data = response.json()\n",
    "        raw_response = data[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "        # Update history with user and assistant messages\n",
    "        #history.append({\"role\": \"user\", \"content\": prompt})\n",
    "        #history.append({\"role\": \"assistant\", \"content\": raw_response})\n",
    "\n",
    "        reply = raw_response\n",
    "    except (KeyError, IndexError, json.JSONDecodeError) as e:\n",
    "        print(\"Error parsing response:\", e)\n",
    "        return None\n",
    "    \n",
    "    evaluateIt = evaluate(prompt, reply, history)\n",
    "\n",
    "    if evaluateIt.accepted:\n",
    "        print(\"Passed evaluation of LLM1 - returning reply\")\n",
    "    else:\n",
    "        print(\"Failed evaluation of LLM1 - reevaluating\")\n",
    "        reply = rerun(prompt,reply,history,evaluateIt.reasoning)\n",
    "    \n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ef1a7703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7869\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7869/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing response: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\marvi\\workspace\\agentic_ai\\.venv\\Lib\\site-packages\\gradio\\queueing.py\", line 626, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\marvi\\workspace\\agentic_ai\\.venv\\Lib\\site-packages\\gradio\\route_utils.py\", line 350, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<11 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\marvi\\workspace\\agentic_ai\\.venv\\Lib\\site-packages\\gradio\\blocks.py\", line 2250, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<8 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\marvi\\workspace\\agentic_ai\\.venv\\Lib\\site-packages\\gradio\\blocks.py\", line 1755, in call_function\n",
      "    prediction = await fn(*processed_input)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\marvi\\workspace\\agentic_ai\\.venv\\Lib\\site-packages\\gradio\\utils.py\", line 884, in async_wrapper\n",
      "    response = await f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\marvi\\workspace\\agentic_ai\\.venv\\Lib\\site-packages\\gradio\\chat_interface.py\", line 551, in __wrapper\n",
      "    return await submit_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\marvi\\workspace\\agentic_ai\\.venv\\Lib\\site-packages\\gradio\\chat_interface.py\", line 925, in _submit_fn\n",
      "    response = await anyio.to_thread.run_sync(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        self.fn, *inputs, limiter=self.limiter\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\marvi\\workspace\\agentic_ai\\.venv\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        func, args, abandon_on_cancel=abandon_on_cancel, limiter=limiter\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\marvi\\workspace\\agentic_ai\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2476, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\marvi\\workspace\\agentic_ai\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 967, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"C:\\temp\\ipykernel_9432\\3228497550.py\", line 43, in chat\n",
      "    if evaluateIt.accepted:\n",
      "       ^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'NoneType' object has no attribute 'accepted'\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
